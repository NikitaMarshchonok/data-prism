# src/data_analyzer.py
def analyze_data(data):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤.
    :param data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
    :return: —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏ –∏ —Å–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    """
    # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns
    stats = {}
    for col in numeric_columns:
        stats[col] = {
            'mean': data[col].mean(),
            'median': data[col].median(),
            'std': data[col].std(),
            'min': data[col].min(),
            'max': data[col].max()
        }
    return stats, numeric_columns
# src/data_analyzer.py

def analyze_missing_values(data):
    """
    –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É.
    :param data: DataFrame
    :return: —Å–ª–æ–≤–∞—Ä—å {—Å—Ç–æ–ª–±–µ—Ü: (–∫–æ–ª-–≤–æ, %)}
    """
    total_rows = len(data)
    missing_info = {}
    for col in data.columns:
        missing_count = data[col].isnull().sum()
        missing_percent = round((missing_count / total_rows) * 100, 2)
        if missing_count > 0:
            missing_info[col] = {
                'count': missing_count,
                'percent': missing_percent
            }
    return missing_info


import plotly.figure_factory as ff

def plot_correlation_heatmap(data):
    """
    –°—Ç—Ä–æ–∏—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.
    :param data: DataFrame
    :return: HTML –≥—Ä–∞—Ñ–∏–∫ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
    """
    corr = data.corr(numeric_only=True)
    z = corr.values.round(2).tolist()
    x = corr.columns.tolist()
    y = corr.index.tolist()

    fig = ff.create_annotated_heatmap(z, x=x, y=y, colorscale='Blues')
    fig.update_layout(
        title="üß† –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞",
        title_font_size=22,
        margin=dict(t=50, l=0, r=0, b=0),
        width=800, height=600
    )
    return fig.to_html(full_html=False, include_plotlyjs='cdn')

def detect_categorical_columns(data, max_unique=15):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã"""
    return [col for col in data.columns if data[col].dtype == 'object' or data[col].nunique() <= max_unique]


import plotly.express as px

def analyze_categorical_column(data, column, top_n=5):
    """–°–æ–∑–¥–∞—ë—Ç –≥—Ä–∞—Ñ–∏–∫ –∏ —Ç–∞–±–ª–∏—Ü—É —Ç–æ–ø –∑–Ω–∞—á–µ–Ω–∏–π"""
    value_counts = data[column].value_counts().nlargest(top_n)
    fig = px.bar(
        x=value_counts.index,
        y=value_counts.values,
        labels={'x': column, 'y': '–ß–∞—Å—Ç–æ—Ç–∞'},
        title=f'üî† –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π: {column}',
        color_discrete_sequence=['#00AEEF']
    )
    fig.update_layout(height=400, template='plotly_white')
    return value_counts.to_dict(), fig.to_html(full_html=False, include_plotlyjs='cdn')



def describe_column_types(data):
    result = {}
    for col in data.columns:
        dtype = str(data[col].dtype)
        nunique = data[col].nunique()
        result[col] = {
            "dtype": dtype,
            "unique": nunique
        }
    return result


# src/data_analyzer.py

import numpy as np

def generate_description_for_column(data, column):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∏—Å–ª–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞.
    """
    series = data[column].dropna()
    desc = ""

    if not np.issubdtype(series.dtype, np.number):
        return f"–°—Ç–æ–ª–±–µ—Ü <b>{column}</b> –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º, –ø–æ—ç—Ç–æ–º—É –≥—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω –±–µ–∑ —á–∏—Å–ª–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è."

    mean = series.mean()
    median = series.median()
    std = series.std()
    min_val = series.min()
    max_val = series.max()
    count = len(series)

    skewness = series.skew()
    outliers = ((series < (mean - 3 * std)) | (series > (mean + 3 * std))).sum()

    desc += f"–ü—Ä–∏–∑–Ω–∞–∫ <b>{column}</b> —Å–æ–¥–µ—Ä–∂–∏—Ç {count} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. "
    desc += f"–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {mean:.2f}, –º–µ–¥–∏–∞–Ω–∞: {median:.2f}, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {std:.2f}. "
    desc += f"–ú–∏–Ω–∏–º—É–º: {min_val}, –º–∞–∫—Å–∏–º—É–º: {max_val}. "

    # –î–æ–±–∞–≤–∏–º –æ—Ü–µ–Ω–∫—É —Å–∏–º–º–µ—Ç—Ä–∏–∏
    if skewness < -1:
        desc += "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–µ—Ç —Å–∏–ª—å–Ω—É—é –ª–µ–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—é—é –∞—Å–∏–º–º–µ—Ç—Ä–∏—é. "
    elif skewness < -0.5:
        desc += "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–º–Ω–æ–≥–æ —Å–∫–æ—à–µ–Ω–æ –≤–ª–µ–≤–æ. "
    elif skewness < 0.5:
        desc += "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º—É. "
    elif skewness < 1:
        desc += "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–º–Ω–æ–≥–æ —Å–∫–æ—à–µ–Ω–æ –≤–ø—Ä–∞–≤–æ. "
    else:
        desc += "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–µ—Ç —Å–∏–ª—å–Ω—É—é –ø—Ä–∞–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—é—é –∞—Å–∏–º–º–µ—Ç—Ä–∏—é. "

    if outliers > 0:
        desc += f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤—ã–±—Ä–æ—Å–æ–≤: {outliers} (–∑–Ω–∞—á–µ–Ω–∏—è –≤–Ω–µ 3œÉ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ)."

    return desc

import pandas as pd
import re

'''def detect_time_columns(df):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≥–æ–¥–∞, –¥–∞—Ç—ã, —Å–µ–∑–æ–Ω—ã).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {–∏–º—è_–∫–æ–ª–æ–Ω–∫–∏: —Ç–∏–ø ['year', 'date', 'season']}
    """
    time_columns = {}

    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            time_columns[col] = 'date'
            continue

        if pd.api.types.is_numeric_dtype(df[col]):
            if df[col].between(1900, 2100).mean() > 0.8:
                time_columns[col] = 'year'
                continue

        if df[col].dtype == 'object':
            try:
                parsed = pd.to_datetime(df[col], errors='coerce')
                if parsed.notna().mean() > 0.8:
                    time_columns[col] = 'date'
                    continue
            except:
                pass

            if re.search(r'season|–≥–æ–¥|year', col.lower()):
                time_columns[col] = 'season'

    return time_columns'''
def detect_time_columns(df):
    time_cols = []

    for col in df.columns:
        try:
            parsed = pd.to_datetime(df[col], errors='coerce')
            non_null_ratio = parsed.notnull().mean()

            # –£—Å–ª–æ–≤–∏–µ: —Ö–æ—Ç—è –±—ã 70% –∑–Ω–∞—á–µ–Ω–∏–π –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –∫–∞–∫ datetime
            if non_null_ratio > 0.7:
                # –ò —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö: –≥–æ–¥, —á–∏—Å–ª–æ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–æ–π –º–µ–Ω—å—à–µ 4 —Å–∏–º–≤–æ–ª–æ–≤
                if not pd.api.types.is_numeric_dtype(df[col]) and df[col].astype(str).str.len().median() >= 4:
                    time_cols.append(col)
        except Exception:
            continue

    return time_cols


# src/data_analyzer.py

def convert_time_columns(df):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—â–µ—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç datetime.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π DataFrame –∏ —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫.
    """
    time_cols = []
    for col in df.columns:
        if any(x in col.lower() for x in ['date', 'time', 'timestamp', 'year']):
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
                time_cols.append(col)
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É '{col}' –≤ datetime: {e}")
    return df, time_cols

